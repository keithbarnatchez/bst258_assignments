---
title: "Problem Set #1"
subtitle: "BST 258: Causal Inference -- Theory and Practice"
author: "Keith Barnatchez"
date: ""
format:
  pdf:
    documentclass: scrartcl
    papersize: letter
    fontsize: 11pt
    geometry:
      - margin=1in
      - heightrounded
    number-sections: false
    colorlinks: true
    link-citations: true
    callout-appearance: simple
    callout-icon: false
    # figure options
    fig-width: 6
    fig-asp: 0.618
    fig-cap-location: bottom
    # code block options
    code-line-numbers: false
    code-block-bg: false
    highlight-style: nord
---

```{r, echo=FALSE, include=FALSE}
library(tidyverse)
library(foreach)
library(doParallel)
```

**Link to the repo for this HW**: `https://github.com/keithbarnatchez/bst258_assignments`

## Question 1

Done. Thanks for the template!

## Question 2

Here, we'll consider a completely randomized experiment with $i=1,\dots,n$ units, $m$ of which are treated. We set $A_i=1$ when unit $i$ is treated.

### Part (a)

We aim to find the marginal distributin of $A$.

::: {.callout-warning title="Solution"}
Without conditioning on any other subject's treatment status, the a randombly sampled subject has an $m/n$ probability of being treated. Specifically,
\begin{align*}
P(A=1) = \frac{m}{n}
\end{align*}
:::

### Part (b)

Here, we aim to find the joint distribution of $A_i$ and $A_j$, where $i \neq j$. 

::: {.callout-warning title="Solution"}
Notice
\begin{align*}
P(A_i=1,A_j=1) &= P(A_j=1|A_i=1)P(A_i=1) = \left(\frac{m-1}{n-1}\right)\frac{m}{n} \\
P(A_i=1,A_j=0) &= P(A_j=0|A_i=1)P(A_i=1) = \left(\frac{n-m}{n-1}\right)\frac{m}{n} \\
P(A_i=0,A_j=1) &= P(A_j=1|A_i=0)P(A_i=0) = \left(\frac{m}{n-1}\right)\frac{n-m}{n} \\
P(A_i=0,A_j=0) &= P(A_j=0|A_i=0)P(A_i=0) = \left(\frac{n-m-1}{n-1}\right)\frac{n-m}{n}
\end{align*}
:::

### Part (c)

We'll first find $\text{Var}(A_i)$.

::: {.callout-warning title="Solution"}
$$
\begin{aligned}
\text{Var}(A_i) &= \mathbb{E}(A_i^2) - \mathbb{E}(A_i)^2 \\
&= \mathbb{E}(A_i) - \mathbb{E}(A_i)^2 \\
&= \frac{m}{n} - \left(\frac{m}{n}\right)^2 \\
&= \frac{m}{n}\left(1 - \frac{m}{n}\right)
\end{aligned}
$$
:::

Next, we'll find $\text{Cov}(A_i,A_j)$.

::: {.callout-warning title=""}
$$
\begin{aligned}
\text{Cov}(A_i,A_j) &= \mathbb{E}[A_i A_j] - \mathbb{E}[A_i]\mathbb{E}[A_j] \\
&= \mathbb{E}_{A_j} \mathbb{E}(A_i A_j | A_j) - \left(\frac{m}{n}\right)^2 \\
&= \mathbb{E}(A_i A_j | A_j = 1)\mathbb{P}(A_j=1) + \mathbb{E}(A_i A_j | A_j = 0)\mathbb{P}(A_j=0)  - \left(\frac{m}{n}\right)^2 \\
&= \mathbb{E}(A_i | A_j = 1)\mathbb{P}(A_j=1)  - \left(\frac{m}{n}\right)^2  \\
&= \frac{m-1}{n-1}\frac{m}{n} - \left(\frac{m}{n}\right)^2 \\
&= \frac{m}{n}\left(\frac{m-1}{n-1} - \frac{m}{n}\right)
\end{aligned}
$$
:::
The covariance expression is intuitive. If we keep $m/n$ fixed as $n$ increases (and our finite population approaches a superpopulation), notice the covariance tends to 0.

### Part (d)

**If the potential outcomes are random**

$$
\begin{aligned}
\mathbb{E}(\theta^\text{ATT}) &= \mathbb{E} \left( \frac{1}{m} \sum_{i=1}^n A_i (Y_i(1) - Y_i(0)) \right) \\
&= \frac{1}{m} \sum_{i=1}^n \mathbb{E}(A_i (Y_i(1) - Y_i(0))) \\
&= \frac{1}{m} \sum_{i=1}^n [\mathbb{E}(A_iY_i(1)) - \mathbb{E}(A_iY_i(0))] \\
&= \frac{1}{m} \sum_{i=1}^n [\mathbb{E}(A_i)\mathbb{E}(Y_i(1)|A_i=1) - \mathbb{E}(A_i)\mathbb{E}(Y_i(0)|A_i=1)] \\
&= \frac{m/n}{m} \sum_{i=1}^n [\mathbb{E}(Y_i(1)|A_i=1) - \mathbb{E}(Y_i(0)|A_i=1)] \\
&= \frac{1}{n} \sum_{i=1}^n \mathbb{E}[Y_i(1) - Y_i(0)|A_i=1] \\
&= \mathbb{E}[Y_i(1) - Y_i(0)|A_i=1] \\
&= \mathbb{E}[Y_i(1) - Y_i(0)] \ \ \ \ \ \ \ \ \ \text{(By randomization)}
\end{aligned}
$$
Then the expected value of the sample ATT is the population ATT, which is the same thing as the ATE in a randomized trial as the treated/untreated populations are by construction the same in expectation.

**If the potential outcomes are fixed**

Notice

$$
\begin{aligned}
\mathbb{E}(\theta^\text{ATT}) &= \mathbb{E} \left( \frac{1}{m} \sum_{i=1}^n A_i (Y_i(1) - Y_i(0)) \right) \\
&= \frac{1}{m} \sum_{i=1}^n \mathbb{E}[A_i (Y_i(1) - Y_i(0))] \\
&= \frac{1}{m} \sum_{i=1}^n  (Y_i(1) - Y_i(0))\mathbb{E}(A_i) \\
&= \frac{1}{m} \sum_{i=1}^n  (Y_i(1) - Y_i(0))\frac{m}{n} \\
&= \frac{1}{n} \sum_{i=1}^n  (Y_i(1) - Y_i(0))
\end{aligned}
$$
When the potential outcomes are fixed, the expectation of the sample ATT equals the sample ATE.

## Quesion 3

We'll first show $\mathbb{V}(Y_i(1)) = \mathbb{V}(Y_i(0))$.

::: {.callout-warning title="Solution"}
\begin{align*}
\mathbb{V}(Y_i(1)) &= \mathbb{V}(Y_i(0) + \theta) \\
&= \mathbb{V}(Y_i(0)) + \mathbb{V}(\theta) \\
&= \mathbb{V}(Y_i(0))
\end{align*}
where the last 2 lines hold because $\theta$ is a constant.
:::

Next, we'll show $\rho(Y_i(1),Y_i(0)) = 1$.

::: {.callout-warning title="Solution"}
First, notice by the bilinearity of covariances,
\begin{align*}
\text{Cov}(Y_i(1),Y_i(0)) &= \text{Cov}(Y_i(0) + \theta,Y_i(0)) \\
&= \text{Cov}(Y_i(0),Y_i(0)) \\
&= \mathbb{V}(Y_i(0)) = \mathbb{V}(Y_i(1))
\end{align*}
Finally, we have
\begin{align*}
\rho(Y_i(1),Y_i(0)) &= \frac{\text{Cov}(Y_i(1),Y_i(0))}{\sqrt{\mathbb{V}(Y_i(1))\mathbb{V}(Y_i(0))}} \\
&= \frac{\mathbb{V}(Y_i(0))}{\sqrt{\mathbb{V}(Y_i(0))\mathbb{V}(Y_i(0))}} \\
&= 1
\end{align*}
:::

## Question 4

::: {.callout-warning title="Solution"}
Notice there is no optimal strategy since the cups are placed on the table randomly. We can think of this problem in terms of an "urn design." Specifically, suppose there are $N=8$ total cups of tea in an urn. $n=4$ of these cups are filled with tea first, and then milk. The remaining $N-n=4$ cups are filled with milk first, and then tea. We'll draw $m=4$ cups from the urn. Selecting a cup with tea first is a "success." 

Under this framing, note that the distribution of the number of successes is given by a hypergeometric distribution. Let $X$ be a random variable denoting the number of successes, or cups with tea first we identify correctly. Then,  
$$
X \sim \text{Hypergeometric}(N=8, K=4, n=4)
$$

Using R, we can print the probabilities below (the `dhyper` function uses a slightly different parameterization):

```{r}
m <- 4 # number of cups with tea poured first
n <- 4 # number of cups with milk poured first
k <- 0:4 # number of correct guesses

# Calculate probabilities for k = 0, 1, 2, 3, 4
probs <- dhyper(k, m, n, m)

# Print the probabilities
names(probs) <- paste0("P(X = ", k, ")")
probs
```

:::

## Question 5

### Part a

::: {.callout-warning title=""}
The main factor contributing to this result is that small stones appear to be easier to treat (notice the higher relative success rate when stratifying by either treatment), and that of the patients asigned to Treatment B, 270/350 had small stones compared to just 87/350 for Treatment A. Thus, even though Treatment A had a higher empirical success rate for treating either type of stone, since many more "hard to treat" patients were assigned to Treatment A,  its overall empirical efficacy was lower.
:::

### Part b

For tractability, we'll assume that participants report their sex at birth (male or female) so that we have four total strata. Consider the following table, which is admittedly contrived but satisfies the constraint: 

\begin{table}[h]
\centering
\begin{tabular}{lccc} 
\toprule
Stone & Gender & Treatment A & Treatment B \\
\midrule
Small & Female & 80/81 (98.7\%) & 1/1 (100\%) \\
Small & Male & 1/6 (16.7\%) & 233/269 (87/3\%) \\
Large & Female & 191/192 (99.5\%) & 1/1 (100\%) \\
Large & Male & 1/71 (1.4\%) & 54/79 (68.4\%) \\
\bottomrule
\end{tabular}
\end{table}

This table is consistent with the original data, and depicts a (contrived) scenario where 1) treatment A is relatively ineffective at treating males, 2) treatment B is only assigned to 1 female with small stones and 1 female with large stones, treating both successfully, with the remaining treatment B slots being assigned to males.

### Part c

::: {.callout-warning title=""}
This phenomenon is typically referred to as Simpson's Paradox. It has broad implications for science, and in particular causal inference, with the largest being that one can make incorrect causal conclusions through crude analyses that don't stratify by important factors. Simpson's Paradox is one motivating factor (among many) for why covariate adjustment is important in causal inference.
:::

## Question 6

I include my code below. I implement a few helper functions for carrying out the simulation:

- `sim_data` simulates potential outcomes according the the data-generating process outlined in the assignment
- `test_sharp_null` simply tests the Fisher's sharp null with an absolute difference in means as the test statistic
- `sim_iter` carries out a single iteration of the simulation (randomly draws $A$ to reveal potential outcomes and then tests sharp and weak nulls)
- `sim_main` carries out the actual simulation exercise

Since both potential outcomes are normally-distributed, a $t-$test is a valid test for the weak null of no mean difference, so I just use the `t.test` function from base R. For the sharp null, I use the permutation test method we discussed in class. To speed things up, I parallelize the main simulation with the `foreach` and ``doParallel` packages. 

My code is below:

```{r}
sim_data <- function(n,mu1,mu0,v1,v0) {
  #' Function for simulating potential outcomes and treatment assignment
  #'
  #' INPUTS:
  #' - n: "Per group" sample size
  #' - mu1 and mu0: Pot. outcome means under tmt and no tmt
  #' - v1 and v0: Pot. outcome variances under tmt and no tmt
  #' 
  #' OUTPUTS:
  #' - A dataframe with columns Y1, Y0
  #'
  
  # Simulate potential outcomes
  Y1 <- rnorm(2*n,mean=mu1,sd=sqrt(v1))
  Y0 <- rnorm(2*n,mean=mu0,sd=sqrt(v0))

  # Hide potential outcomes depending on tmt status
  df <- data.frame(Y1,Y0)
  
  return(df)
}

test_sharp_null <- function(df, B=1e3,
                            alpha=0.05) {
  #' Function for testing the sharp null hypothesis of no treatment effect
  #'
  #' INPUTS:
  #' - df: Dataframe from sim_data() that has been added columns A and Y thru sim_iter
  #' - B: Number of replications
  #'
  #' OUTPUTS:
  #' - 1 if reject, 0 otherwise
  #'

  # Calculate test statistic (absolute difference in means)
  test_stat <- abs(mean(df$Y[df$A == 1]) - mean(df$Y[df$A == 0]))
  
  # Compute the test statistic (abs difference in means) for each permuted dataset
  test_stats <- replicate(B, {
    A_perm <- sample(df$A) # shuffle A
    abs( mean(df$Y[A_perm == 1]) -  mean(df$Y[A_perm == 0]))
  })
  
  # Get p-value (empirical prob of observing a test statistic as or more extreme 
  # as the observed one)
  pval <- mean(test_stats >= test_stat)
  
  # Return 1 if reject, 0 otherwise
  ifelse(pval < alpha, 1, 0)
  
  # Return 1 if reject, 0 otherwise
  return(ifelse(pval < alpha, 1, 0))
  
}

sim_iter <- function(df, p, B=1e4,
                     alpha=0.05) {
  #' Function for performing single iteration of simulation
  #'
  #' INPUTS:
  #' - n: "Per group" sample size
  #' - mu1 and mu0: Pot. outcome means under tmt and no tmt
  #' - v1 and v0: Pot. outcome variances under tmt and no tmt
  #' - p: Probability of treatment
  #' - B: Number of simulation iterations
  #'
  #' OUTPUTS:
  #' - A dataframe with columns n, nsim, B, and pval
  #'
  
  # Simulate data (shuffle the treatment assignments)
  df <- df %>% mutate(A = rbinom(nrow(df),1,p)) %>%
    mutate(Y = ifelse(A==1,Y1,Y0))
  
  # Test the sharp null
  sharp_rej <- test_sharp_null(df,B,alpha) # ifelse(sharp_rej < alpha, 1, 0)
  
  # Test the weak null (can just do a t test): extract p-value
  weak_rej <- ifelse(t.test(df$Y ~ df$A)$p.value < alpha, 1, 0) 
  
  # Store results
  results <- data.frame(sharp_rej,weak_rej,n=nrow(df)/2)
  
  return(results)
}

sim_main <- function(n_grid,
                     mu1,mu0,v1,v0,p,
                     B=1e4,
                     alpha=0.05,
                     nsim=1e3) {
  #' Function for performing simulation
  #'
  #' INPUTS:
  #' - n: "Per group" sample size
  #' - mu1 and mu0: Pot. outcome means under tmt and no tmt
  #' - v1 and v0: Pot. outcome variances under tmt and no tmt
  #' - p: Probability of treatment
  #' - B: Number of simulation iterations
  #'
  #' OUTPUTS:
  #' - A dataframe with columns n, nsim, B, and pval
  #'
  
  # Setup cluster
  no_cores <- detectCores() - 2 
  registerDoParallel(no_cores)
  
  # Run the simulation
  results_list <- foreach(n=n_grid) %dopar% {
    
    # Simulate initial dataset of potential outcomes
    df <- sim_data(n,mu1,mu0,v1,v0)
    
    # Test shar and weak null nsim times
    replicate(nsim, sim_iter(df, p, B, alpha), simplify = FALSE)
  }
  
  stopImplicitCluster()
  
  # Flatten the list and combine into one dataframe
  results <- do.call(rbind, unlist(results_list, recursive = FALSE))
  
  return(results)

}
```

Below is my code for implementing the simulation:

```{r,cache=TRUE}
# Fix parameter values
nsim <- 1e3 ; B <- 1e4 ; alpha <- 0.05
mu1 <- 1/10 ; mu0 <- 0 ; v1 <- 1/16 ; v0 <- 1/16 ; p <- 0.5

# Set up grid of sample sizes for sim_main
n_grid <- c(10, 25, 50, 100, 250)

results_df <- sim_main(n_grid=n_grid,
                       mu1=mu1,mu0=mu0,v1=v1,v0=v0,p=p,
                       B=B,alpha=alpha,nsim=nsim)
```

And my code for plotting the results:

```{r}
# Reshape the data into long format using pivot_longer and then take average of
# rej by n and null
results_df_long <- results_df %>%
  pivot_longer(cols=c(sharp_rej,weak_rej), names_to="null", values_to="rej") %>%
   mutate(null = ifelse(null == "sharp_rej", "Sharp Null", "Weak Null")) %>%
  group_by(n,null) %>% summarize(power=mean(rej))

# # Plot the results
results_df_long %>%
  ggplot(aes(x=n, y=power, group=as.factor(null),color=as.factor(null))) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = n_grid) +
  labs(title="Power for testing Sharp and Weak Null Hypotheses",
       x="Sample Size", y="Rejection Rate",
       color='Null hypothesis') +
  theme_minimal() +
  theme(legend.position='bottom')
```

A couple observations:

1. As $n$ increases, power tends to increase across nulls, which is unsurprisng. Do note there is an opportunity for power to fluctuate, since at each sample size power is based on a *single* dataset of potential outcomes (where the treatment assignments are what's simulated)
2. Perhaps more surprisingly, at each sample size both tests appear to have roughly the same power. This makes sense when we consider that, while the sharp null is generally easier to reject than the weak null, the means by which we **test** the sharp null---through a permutation test---is actually conservative (permutation tests tend to be conservative). In net, this appears to cancel out any gains in power we'd otherwise expect

## Question 7

### Part a

Let 
$$
\ell(\alpha,\beta) = \frac{1}{2n}\sum_{i=1}^n (Y_i - \alpha - \beta A_i)^2
$$
Since the loss function is convex, we can find the minimizer by setting the first-order conditions to zero (without needing to check the second-order conditions). That is, we want to solve
$$
\begin{aligned}
\frac{\partial \ell(\alpha,\beta)}{\partial \beta} &= 0 \iff  \frac{1}{n}\sum_{i=1}^n A_i(Y_i - \alpha - \beta A_i) = 0 \\
\frac{\partial \ell(\alpha,\beta)}{\partial \alpha} &= 0 \iff  \frac{1}{n}\sum_{i=1}^n (Y_i - \alpha - \beta A_i) = 0
\end{aligned}
$$
First, notice the first-order condition for $\beta$ implies
$$
\begin{aligned}
 \hat \beta &= \frac{P_n (AY)}{P_n(A)} - \hat \alpha
\end{aligned}
$$
where $P_n$ is the sample mean operator. To obtain $\hat \alpha$, first notice the two first-order conditions imply
$$
\begin{aligned}
&\frac{1}{n}\sum_{i=1}^n (Y_i - \alpha - \beta A_i) - \frac{1}{n}\sum_{i=1}^n A_i(Y_i - \alpha - \beta A_i) = 0 \\
&\iff \frac{1}{n}\sum_{i=1}^n (1-A_i)(Y_i - \alpha - \beta A_i) = 0 \\
& \iff P_n((1-A)Y) - \hat \alpha P_n(1-A) - \hat \beta \underbrace{P_n(A(1-A))}_{=0} = 0 \\ 
& \iff \hat \alpha = \frac{P_n((1-A)Y)}{P_n(1-A)}
\end{aligned}
$$
Above, I use the fact that $P_n(A(1-A)) = 0$ when $A$ is binary. Thus, we have

$$
\begin{aligned}
\hat \beta &= \frac{P_n (AY)}{P_n(A)} - \frac{P_n((1-A)Y)}{P_n(1-A)}
\end{aligned}
$$
Notice that, in the setting of a completely randomized experiment, the OLS estimator of $\beta$ amounts to the difference in means estimator of the ATE.

### Part b

Yes! As we argued in part (a), in this context $\hat \beta$ reduces to the difference in means estimator, which we argued in class is a valid (in the sense of being unbiased and asymptotically normal) estimator of the ATE.